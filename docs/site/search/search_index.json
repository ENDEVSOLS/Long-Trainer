{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"LongTrainer - Production-Ready LangChain <p>      Visit Blog Post    </p>"},{"location":"#welcome-to-longtrainer-documentation","title":"Welcome to LongTrainer Documentation","text":"<p>Welcome to the official documentation for LongTrainer, a sophisticated extension of the LangChain framework designed for managing multiple bots and providing isolated, context-aware chat sessions. This documentation is intended to guide you through the installation, configuration, and operation of LongTrainer to help you effectively integrate conversational AI into your systems.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>To begin using LongTrainer, the first step is to install it. Detailed installation instructions, including prerequisites and step-by-step guidance, can be found on our Installation page.</p>"},{"location":"#install-longtrainer","title":"Install LongTrainer","text":"<p>To quickly install LongTrainer, you can use the following pip command:</p> <pre><code>pip install longtrainer\n</code></pre> <p> </p>"},{"location":"about/","title":"LongTrainer","text":"<p>Introducing LongTrainer, a sophisticated extension of the LangChain framework designed specifically for managing multiple bots and providing isolated, context-aware chat sessions. Ideal for developers and businesses looking to integrate complex conversational AI into their systems, LongTrainer simplifies the deployment and customization of LLMs.</p>"},{"location":"about/#features","title":"Features \ud83c\udf1f","text":"<ul> <li>\u2705 Long Memory: Retains context effectively for extended interactions.</li> <li>\u2705 Multi-Bot Management: Easily configure and manage multiple bots within a single framework, perfect for scaling across various use cases</li> <li>\u2705 Isolated Chat Sessions: Each bot operates within its own session, ensuring interactions remain distinct and contextually relevant without overlap.</li> <li>\u2705 Context-Aware Interactions:  Utilize enhanced memory capabilities to maintain context over extended dialogues, significantly improving user experience</li> <li>\u2705 Scalable Architecture: Designed to scale effortlessly with your needs, whether you're handling hundreds of users or just a few.</li> <li>\u2705 Enhanced Customization: Tailor the behavior to fit specific needs.</li> <li>\u2705 Memory Management: Efficient handling of chat histories and contexts.</li> <li>\u2705 GPT Vision Support: Integration Context Aware GPT-powered visual models.</li> <li>\u2705 Different Data Formats: Supports various data input formats.</li> <li>\u2705 VectorStore Management: Advanced management of vector storage for efficient retrieval.</li> </ul>"},{"location":"about/#diverse-use-cases","title":"Diverse Use Cases:","text":"<ul> <li>\u2705 Enterprise Solutions: Streamline customer interactions, automate responses, and manage multiple departmental bots from a single platform.</li> <li>\u2705 Educational Platforms: Enhance learning experiences with AI tutors capable of maintaining context throughout sessions.</li> <li>\u2705 Healthcare Applications: Support patient management with bots that provide consistent, context-aware interactions.</li> </ul>"},{"location":"about/#works-for-all-langchain-supported-llm-and-embeddings","title":"Works for All Langchain Supported LLM and Embeddings","text":"<ul> <li>\u2705 OpenAI (default)</li> <li>\u2705 VertexAI</li> <li>\u2705 HuggingFace</li> <li>\u2705 AWS Bedrock</li> <li>\u2705 Groq</li> <li>\u2705 TogetherAI</li> </ul>"},{"location":"chat_management/","title":"Chat Management","text":""},{"location":"chat_management/#chat-management-in-longtrainer","title":"Chat Management in LongTrainer","text":"<p>LongTrainer provides comprehensive tools for managing chat sessions, including the creation of new chats, vision-enabled chats, and viewing past chat interactions. This guide will demonstrate how to effectively use these tools to enhance interaction and manage conversations.</p>"},{"location":"chat_management/#creating-new-chat-sessions","title":"Creating New Chat Sessions","text":"<p>LongTrainer allows you to start new chat sessions where each session is treated uniquely, maintaining its context independently of others. This helps in managing multiple ongoing conversations without overlap.</p>"},{"location":"chat_management/#start-a-new-text-chat","title":"Start a New Text Chat","text":"<p>To begin a new text chat session, simply initialize a chat session and then send queries to get responses.</p> <p>Example Usage:</p> <pre><code># Start a new chat session\nchat_id = trainer.new_chat(bot_id)\n\n# Send a query and get a response\nquery = 'Your query here'\nresponse = trainer.get_response(query, bot_id, chat_id)\nprint('Response: ', response)\n</code></pre>"},{"location":"chat_management/#start-a-new-vision-chat","title":"Start a New Vision Chat","text":"<p>For chats that require visual context, LongTrainer supports vision chat sessions. These sessions can process and respond based on the visual data provided.</p> <p>Example Usage:</p> <pre><code># Initialize a new vision chat session\nvision_chat_id = trainer.new_vision_chat(bot_id)\n\n# Prepare your query and image paths\nquery = 'What is depicted in this image?'\nimage_paths = ['path/to/image.jpg']\n\n# Send a vision query and get a response\nresponse = trainer.get_vision_response(query, image_paths, bot_id, vision_chat_id)\nprint('Response: ', response)\n</code></pre>"},{"location":"chat_management/#managing-chat-history","title":"Managing Chat History","text":"<p>LongTrainer offers functionalities to list all chats and retrieve detailed histories of individual chat sessions, which is crucial for monitoring and improving the interaction quality over time.</p>"},{"location":"chat_management/#list-all-chats","title":"List All Chats","text":"<p>You can list all chat sessions associated with a specific bot, providing a snapshot of each session\u2019s initial interaction.</p> <p>Example Usage:</p> <pre><code># List all chats for a specific bot\ntrainer.list_chats(bot_id)\n</code></pre>"},{"location":"chat_management/#retrieve-detailed-chat-history","title":"Retrieve Detailed Chat History","text":"<p>To access the full conversation of a specific chat session, use the method that fetches detailed history, allowing review and analysis of past interactions.</p> <p>Example Usage:</p> <pre><code># Retrieve and display the full conversation details of a specific chat session\ndetailed_chat = trainer.get_chat_by_id(chat_id)\nfor message in detailed_chat:\n    print(f\"Q: {message['question']}\")\n    print(f\"A: {message['answer']}\")\n</code></pre>"},{"location":"chat_management/#exporting-chat-histories","title":"Exporting Chat Histories","text":"<p>For further analysis or training, you may export chat histories to CSV files. This feature is helpful for data retention policies and training models on historical data.</p> <p>Example Usage:</p> <pre><code># Export chat histories to a CSV file\nexported_file_path = trainer._export_chats_to_csv(detailed_chat, bot_id)\nprint(f\"Chat history exported to: {exported_file_path}\")\n</code></pre>"},{"location":"chat_management/#training-on-chat-data","title":"Training on Chat Data","text":"<p>To improve the conversational AI model, LongTrainer can train on new, unprocessed chats, continually enhancing the bot\u2019s response quality.</p> <p>Example Usage:</p> <pre><code># Train the bot on newly gathered chat data\ntraining_result = trainer.train_chats(bot_id)\nprint(training_result)\n</code></pre>"},{"location":"creating_instance/","title":"Creating an Instance","text":""},{"location":"creating_instance/#creating-an-instance-of-longtrainer","title":"Creating an Instance of LongTrainer","text":"<p>To start using LongTrainer, you need to initialize an instance of the <code>LongTrainer</code> class. This instance will allow you to manage chatbots, handle conversational states, and interact with your MongoDB to store and retrieve data securely and efficiently.</p>"},{"location":"creating_instance/#initialization-code-snippet","title":"Initialization Code Snippet","text":"<pre><code>from longtrainer.trainer import LongTrainer\n\n# Initialize the LongTrainer with default parameters\ntrainer = LongTrainer()\n</code></pre>"},{"location":"creating_instance/#constructor-parameters","title":"Constructor Parameters","text":"<p>The <code>LongTrainer</code> constructor accepts several parameters that allow you to customize its behavior to fit your specific needs:</p> <ul> <li> <p><code>mongo_endpoint</code> (str): The connection string URL to your MongoDB instance. This parameter defaults to <code>'mongodb://localhost:27017/'</code>, pointing to a MongoDB running on the default port on your local machine. Specify a different URL if your MongoDB instance is hosted elsewhere or configured differently.</p> </li> <li> <p><code>llm</code> (Any): The language learning model (LLM) used for processing queries and generating responses. By default, this is set to <code>None</code>, which means the system will use <code>ChatOpenAI</code> with a GPT-4-Turbo model. You can pass any compatible LLM instance according to your project's requirements.</p> </li> <li> <p><code>embedding_model</code> (Any): This parameter allows you to specify the embedding model used for document vectorization. The default is <code>OpenAIEmbeddings</code>, which is optimized for general-purpose language understanding.</p> </li> <li> <p><code>prompt_template</code> (Any): A template used to generate prompts that guide the LLM in generating appropriate responses. The system uses a predefined template by default, but you can customize this to better suit the nuances of your specific application.</p> </li> <li> <p><code>max_token_limit</code> (int): Specifies the maximum number of tokens (words and characters) that the LLM can handle in a single query. This is set to <code>32000</code> by default, which is typically sufficient for most conversational applications.</p> </li> <li> <p><code>num_k</code> (int): Defines the number of top results (<code>k</code>) retrieved by the document retriever during the search process. The default value is <code>3</code>, balancing performance and relevance.</p> </li> <li> <p><code>chunk_size</code> (int): Determines the size of the text chunks that the <code>TextSplitter</code> processes. The default size is <code>2048</code>, which affects how text is segmented for processing.</p> </li> <li> <p><code>chunk_overlap</code> (int): Defines the overlap size between consecutive text chunks processed by the <code>TextSplitter</code>. This parameter is set to <code>200</code> by default, ensuring that context isn't lost at chunk boundaries.</p> </li> <li> <p><code>encrypt_chats</code> (Bool): A boolean flag that indicates whether chat data should be encrypted before being stored in MongoDB. This is set to <code>False</code> by default for development ease, but it is recommended to enable encryption (<code>True</code>) in production environments to ensure data privacy.</p> </li> <li> <p><code>encryption_key</code> (Any): This parameter is used to initialize the encryption algorithm (Fernet) if <code>encrypt_chats</code> is set to <code>True</code>. It should be a secure key that remains confidential. By default, it is <code>None</code>, and a key will be generated automatically if encryption is enabled.</p> </li> </ul>"},{"location":"creating_instance/#example-with-custom-parameters","title":"Example with Custom Parameters","text":"<pre><code>from longtrainer.trainer import LongTrainer\n\n# Customized LongTrainer initialization\ntrainer = LongTrainer(\n    mongo_endpoint='mongodb://custom-host:27017/',\n    max_token_limit=4096,\n    num_k=3,\n    chunk_size=1024,\n    chunk_overlap=100,\n    encrypt_chats=False,\n)\n</code></pre>"},{"location":"creating_using_bot/","title":"Creating and Using a Bot","text":""},{"location":"creating_using_bot/#creating-and-using-a-bot-with-longtrainer","title":"Creating and Using a Bot with LongTrainer","text":"<p>This guide will walk you through the steps to create a new bot using the LongTrainer framework, add sample data to it, initialize a chat session, and interact with the bot to get responses.</p>"},{"location":"creating_using_bot/#step-1-create-a-new-bot","title":"Step 1: Create a New Bot","text":"<p>First, you'll need to initialize a new bot instance which will generate a unique bot ID. This ID will be used to reference the bot in subsequent operations.</p> <pre><code>from longtrainer.trainer import LongTrainer\n\n# Initialize the LongTrainer instance\ntrainer = LongTrainer()\n\n# Create a new bot and obtain its ID\nbot_id = trainer.initialize_bot_id()\nprint('Bot ID: ', bot_id)\n</code></pre>"},{"location":"creating_using_bot/#step-2-add-sample-data-to-the-bot","title":"Step 2: Add Sample Data to the Bot","text":"<p>Load documents from a specified file path into the bot's memory. This data will be used by the bot to generate responses to queries.</p> <pre><code># Specify the path to your data\npath = 'path/to/your/data'\n\n# Add documents to the bot\ntrainer.add_document_from_path(path, bot_id, use_unstructured=True)\n</code></pre> <p>This method supports unstructured data, making it versatile for various types of textual input.</p>"},{"location":"creating_using_bot/#step-3-initialize-the-bot","title":"Step 3: Initialize the Bot","text":"<p>Configure and initialize the bot with a custom or default prompt template. This template helps guide the conversation and influences the responses generated by the bot.</p> <pre><code># Initialize the bot with the Default Trainer`s prompt template\ntrainer.create_bot(bot_id)\n\n# Define a custom prompt template (optional)\nprompt = \"Custom prompt template for your specific use case.\"\n\n# Initialize the bot with the specified prompt template\ntrainer.create_bot(bot_id, prompt_template=prompt)\n</code></pre>"},{"location":"creating_using_bot/#step-4-start-a-new-chat-session","title":"Step 4: Start a New Chat Session","text":"<p>Begin a new chat session with the bot. This step involves creating a new chat context that will manage the dialogue between the user and the bot.</p> <pre><code># Start a new chat session and get the chat ID\nchat_id = trainer.new_chat(bot_id)\n</code></pre>"},{"location":"creating_using_bot/#step-5-interact-with-the-bot","title":"Step 5: Interact with the Bot","text":"<p>Send a query to the bot and receive a response. You can optionally enable web search to enrich the bot's responses with external information.</p> <pre><code># Define your query\nquery = 'Your query here'\n\n# Send the query and get the response\nresponse = trainer.get_response(query, bot_id, chat_id, uploaded_files=None, web_search=False)\nprint('Response: ', response)\n</code></pre> <p>This function retrieves responses from the bot, which can include content from uploaded files and web search results, enhancing the depth and relevance of the interaction.</p>"},{"location":"creating_using_bot/#handling-responses","title":"Handling Responses","text":"<p>The response from the bot will be based on the input query, the documents loaded into the bot's memory, and the configuration of the bot itself. The response can be further enriched by setting <code>web_search</code> to <code>True</code> or by providing <code>uploaded_files</code> containing additional context.</p>"},{"location":"deleting_bot/","title":"Deleting Bots","text":""},{"location":"deleting_bot/#deleting-bots-in-longtrainer","title":"Deleting Bots in LongTrainer","text":"<p>Managing the lifecycle of bots within LongTrainer includes the capability to securely and thoroughly remove a bot and all its associated data. This is crucial for maintaining data hygiene and ensuring that obsolete or redundant bots do not clutter your system.</p>"},{"location":"deleting_bot/#functionality-overview","title":"Functionality Overview","text":"<p>The <code>delete_chatbot</code> method is designed to remove a bot from the system completely, ensuring that all its data, including documents, chats, and any other related records, are permanently deleted.</p> <p>Method Signature:</p> <pre><code>def delete_chatbot(self, bot_id):\n</code></pre>"},{"location":"deleting_bot/#parameters-description","title":"Parameters Description","text":"<ul> <li>bot_id (str): The unique identifier for the bot that you intend to delete.</li> </ul>"},{"location":"deleting_bot/#deletion-process","title":"Deletion Process","text":"<p>The deletion process follows several steps to ensure that all traces of the bot are removed:</p> <ol> <li>Verify Bot Existence:</li> <li> <p>The method first checks if the bot exists in the system using the provided <code>bot_id</code>. If the bot does not exist, it raises an exception.</p> </li> <li> <p>Delete Database Entries:</p> </li> <li> <p>All documents and data entries associated with the bot are deleted from their respective MongoDB collections (<code>chats</code>, <code>vision_chats</code>, <code>bots</code>).</p> </li> <li> <p>Remove Data Files:</p> </li> <li> <p>Any files or data specific to the bot stored on the filesystem, such as cached data or exported CSV files, are removed.</p> </li> <li> <p>Cleanup In-memory Data:</p> </li> <li>References and objects held in memory that pertain to the bot are cleared to free up resources and prevent any data leaks.</li> </ol>"},{"location":"deleting_bot/#error-handling","title":"Error Handling","text":"<ul> <li>The method includes error handling to manage situations where the bot ID does not exist or there are issues accessing the filesystem to delete files.</li> </ul>"},{"location":"deleting_bot/#example-usage","title":"Example Usage","text":"<pre><code># Specify the bot ID to delete\nbot_id_to_delete = 'your_bot_id_here'\n\n# Attempt to delete the bot\ntry:\n    trainer.delete_chatbot(bot_id_to_delete)\n    print(\"Bot successfully deleted.\")\nexcept Exception as e:\n    print(f\"Failed to delete bot: {e}\")\n</code></pre>"},{"location":"deleting_bot/#considerations","title":"Considerations","text":"<ul> <li>Data Backup: Before deleting a bot, consider backing up any important data or documents associated with the bot if they might be needed later.</li> <li>Irreversibility: Deletion is irreversible. Once a bot is deleted, it cannot be recovered, so ensure that deletion is the desired action before proceeding.</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>To get started just follow this guide:</p> <pre><code>pip install longtrainer\n</code></pre>"},{"location":"installation/#installation-instructions-for-required-libraries-and-tools","title":"Installation Instructions for Required Libraries and Tools","text":""},{"location":"installation/#1-linux-ubuntudebian","title":"1. Linux (Ubuntu/Debian)","text":"<p>To install the required packages on a Linux system (specifically Ubuntu or Debian), you can use the apt package manager. The following command installs several essential libraries and tools:</p> <pre><code>sudo apt install libmagic-dev poppler-utils tesseract-ocr qpdf libreoffice pandoc\n</code></pre>"},{"location":"installation/#2-macos","title":"2. macOS","text":"<p>On macOS, you can install these packages using brew, the Homebrew package manager. If you don't have Homebrew installed, you can install it from brew.sh.</p> <pre><code>brew install libmagic poppler tesseract qpdf libreoffice pandoc\n</code></pre>"},{"location":"integrating_embeddings/","title":"Integrating Embeddings","text":""},{"location":"integrating_embeddings/#integrating-different-embeddings-in-longtrainer","title":"Integrating Different Embeddings in LongTrainer","text":"<p>LongTrainer supports various embedding models that can be utilized to enhance the capabilities of your language models by providing efficient, context-aware text representations. This guide covers how to configure and use different embeddings within LongTrainer, including the default OpenAI embeddings as well as Bedrock and HuggingFace options.</p>"},{"location":"integrating_embeddings/#default-embedding-openai","title":"Default Embedding: OpenAI","text":"<p>OpenAI embeddings are the default option in LongTrainer, known for their robust performance and general applicability across various text processing tasks. There is no need for additional configuration if you choose to use the default settings.</p> <p>Example for default usage:</p> <pre><code>from longtrainer.trainer import LongTrainer\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = 'sk-'\n\n# Initialize LongTrainer with default OpenAI embeddings\ntrainer = LongTrainer(mongo_endpoint='mongodb://localhost:27017/')\n</code></pre>"},{"location":"integrating_embeddings/#aws-bedrock-embeddings","title":"AWS Bedrock Embeddings","text":"<p>For those utilizing AWS services, Bedrock Embeddings offer a highly optimized solution tailored for efficient large-scale embedding tasks. These embeddings are particularly useful for applications requiring integration with AWS ecosystems and data services.</p>"},{"location":"integrating_embeddings/#configuration-example-for-bedrock-embeddings","title":"Configuration Example for Bedrock Embeddings","text":"<pre><code>from langchain_aws import BedrockEmbeddings\nfrom longtrainer.trainer import LongTrainer\n\n# Configure AWS Bedrock embeddings\nbedrock_embeddings = BedrockEmbeddings(\n    model_id=\"amazon.titan-embed-text-v2\", \n    region_name=\"us-east-1\"\n)\n\n# Set up LongTrainer with Bedrock Embeddings\ntrainer = LongTrainer(\n    mongo_endpoint='mongodb://localhost:27017/',\n    chunk_size=1024,\n    encrypt_chats=False,\n    embedding_model=bedrock_embeddings\n)\n</code></pre>"},{"location":"integrating_embeddings/#huggingface-embeddings","title":"HuggingFace Embeddings","text":"<p>HuggingFace offers a diverse range of pre-trained embedding models available through its platform. These embeddings are suitable for those who are looking for specific linguistic traits or need embeddings trained on particular types of data or languages.</p>"},{"location":"integrating_embeddings/#configuration-example-for-huggingface-embeddings","title":"Configuration Example for HuggingFace Embeddings","text":"<pre><code>from langchain_community.embeddings import HuggingFaceBgeEmbeddings\nfrom longtrainer.trainer import LongTrainer\n\n# Initialize HuggingFace embeddings\nembeddings = HuggingFaceBgeEmbeddings(\n    model_name=\"BAAI/bge-small-en\",\n    model_kwargs={\"device\": \"cpu\"},\n    encode_kwargs={\"normalize_embeddings\": True}\n)\n\n# Create a LongTrainer instance with HuggingFace embeddings\ntrainer = LongTrainer(\n    mongo_endpoint='mongodb://localhost:27017/',\n    chunk_size=1024,\n    encrypt_chats=False,\n    embedding_model=embeddings\n)\n</code></pre>"},{"location":"integrating_llms/","title":"Integrating LLMs and Embeddings","text":""},{"location":"integrating_llms/#integrating-multiple-large-language-models-with-longtrainer","title":"Integrating Multiple Large Language Models with LongTrainer","text":"<p>LongTrainer is designed to be flexible and extensible, supporting a variety of Large Language Models (LLMs) and embeddings. This allows users to tailor the AI capabilities of their applications to meet specific requirements and leverage the strengths of different AI models.</p>"},{"location":"integrating_llms/#supported-large-language-models-and-embeddings","title":"Supported Large Language Models and Embeddings","text":"<p>LongTrainer currently supports the following LLMs:</p> <ul> <li>\u2705 OpenAI (default)</li> <li>\u2705 VertexAI</li> <li>\u2705 HuggingFace</li> <li>\u2705 AWS Bedrock</li> <li>\u2705 Groq</li> <li>\u2705 TogetherAI</li> </ul> <p>Each of these models can be integrated seamlessly into your LongTrainer setup, providing specialized capabilities and enhancements to your applications.</p>"},{"location":"integrating_llms/#example-integrations","title":"Example Integrations","text":""},{"location":"integrating_llms/#vertexai-integration","title":"VertexAI Integration","text":"<pre><code>from longtrainer.trainer import LongTrainer\nfrom langchain_community.llms import VertexAI\n\n# Initialize the VertexAI model\nllm = VertexAI()\n\n# Create a LongTrainer instance with VertexAI\ntrainer = LongTrainer(mongo_endpoint='mongodb://localhost:27017/', llm=llm)\n</code></pre>"},{"location":"integrating_llms/#togetherai-integration","title":"TogetherAI Integration","text":"<pre><code>from longtrainer.trainer import LongTrainer\nfrom langchain_community.llms import Together\n\n# Configure the TogetherAI model\nllm = Together(\n    model=\"togethercomputer/RedPajama-INCITE-7B-Base\",\n    temperature=0.7,\n    max_tokens=128,\n    top_k=1,\n    # together_api_key=\"...\"\n)\n\n# Create a LongTrainer instance with TogetherAI\ntrainer = LongTrainer(mongo_endpoint='mongodb://localhost:27017/', llm=llm)\n</code></pre>"},{"location":"integrating_llms/#aws-bedrock-integration","title":"AWS Bedrock Integration","text":"<pre><code>from langchain_aws import ChatBedrock\nfrom longtrainer.trainer import LongTrainer\n\n# Initialize the AWS Bedrock model with specific settings\nchat = ChatBedrock(\n    model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n    model_kwargs={\"temperature\": 0.5}\n)\n\n# Set up LongTrainer with AWS Bedrock\ntrainer = LongTrainer(\n    mongo_endpoint='mongodb://localhost:27017/',\n    chunk_size=1024,\n    encrypt_chats=False,\n    llm=chat\n)\n</code></pre>"},{"location":"integrating_llms/#grok-api-integration","title":"Grok API Integration","text":"<pre><code>from longtrainer.trainer import LongTrainer\nfrom langchain_community.llms import ChatGroq\n\n# Configure the Grok API model\nllm = ChatGroq(\n    model=\"llama-3.1-70b-versatile\",\n    temperature=0,\n    max_tokens=1024,\n    model_kwargs={\n        \"top_p\": 1,\n        \"stream\": False\n    },\n    api_key='gsk_...'\n)\n\n# Integrate Grok API with LongTrainer\ntrainer = LongTrainer(mongo_endpoint='mongodb://localhost:27017/', llm=llm)\n</code></pre>"},{"location":"supported_formats/","title":"Supported Document Formats","text":""},{"location":"supported_formats/#supported-document-formats-in-longtrainer","title":"Supported Document Formats in LongTrainer","text":"<p>LongTrainer is designed to accommodate a wide range of document formats, enabling you to leverage diverse data sources to enrich your bot's conversational context. This guide details the supported formats and demonstrates how to add documents from different sources to your bot.</p>"},{"location":"supported_formats/#types-of-supported-documents","title":"Types of Supported Documents","text":"<p>LongTrainer can handle various document types, including structured and unstructured data, ensuring flexibility in how information is ingested and utilized. Here are the document types you can work with:</p> <ul> <li>Text Documents: Includes <code>.txt</code>, <code>.docx</code>, <code>.md</code> (Markdown), and more.</li> <li>Data Sheets: Such as <code>.csv</code>, <code>.xlsx</code>, and <code>.tsv</code> files.</li> <li>Presentations: Including <code>.ppt</code> and <code>.pptx</code>.</li> <li>Web Pages: HTML files and content extracted from URLs.</li> <li>PDFs: Comprehensive support for PDF documents.</li> <li>Images: Text extraction from image files.</li> <li>Other Formats: <code>.epub</code>, <code>.msg</code>, <code>.odt</code>, <code>.org</code>, <code>.rtf</code>, and <code>.rst</code>.</li> </ul>"},{"location":"supported_formats/#adding-documents-to-a-bot","title":"Adding Documents to a Bot","text":"<p>You can add documents to your bot using one of several methods provided by LongTrainer, each tailored to different types of data sources:</p>"},{"location":"supported_formats/#1-from-local-and-network-paths","title":"1. From Local and Network Paths","text":"<p>Add documents directly from file paths, supporting both structured and unstructured data.</p> <p>Example Usage:</p> <pre><code>from longtrainer.trainer import LongTrainer\n\n# Initialize the trainer\ntrainer = LongTrainer()\n\n# Create a new bot\nbot_id = trainer.initialize_bot_id()\n\n# Add documents from a local path\npath = 'path/to/your/document.pdf'\ntrainer.add_document_from_path(path, bot_id, use_unstructured=True)\n</code></pre>"},{"location":"supported_formats/#2-from-web-links","title":"2. From Web Links","text":"<p>Incorporate content directly from the internet by specifying URLs. This method is particularly useful for adding dynamic content from the web to your bot's knowledge base.</p> <p>Example Usage:</p> <pre><code># List of web links\nlinks = ['http://example.com/report1', 'http://example.com/data.csv']\n\n# Add documents from these links\ntrainer.add_document_from_link(links, bot_id)\n</code></pre>"},{"location":"supported_formats/#3-from-search-queries","title":"3. From Search Queries","text":"<p>Utilize search queries to fetch and load content from platforms like Wikipedia, providing a rich source of information for your bot.</p> <p>Example Usage:</p> <pre><code># Search query for Wikipedia\nsearch_query = \"Deep Learning\"\n\n# Add documents from a Wikipedia search\ntrainer.add_document_from_query(search_query, bot_id)\n</code></pre>"},{"location":"supported_formats/#4-custom-loaders","title":"4. Custom Loaders","text":"<p>For advanced use cases, you can use custom loaders to integrate specialized or proprietary data formats.</p> <p>Example Usage:</p> <pre><code># Custom document loader\ndocuments = custom_langchain_loader('path/to/data')\n\n# Add these documents to the bot\ntrainer.pass_documents(documents, bot_id)\n</code></pre>"},{"location":"supported_formats/#supported-file-types-for-unstructured-data","title":"Supported File Types for Unstructured Data","text":"<p>When loading unstructured data, LongTrainer can handle a variety of file types, ensuring you can work with data exactly as it exists within your organization.</p> <p>Supported Unstructured File Types:</p> <ul> <li><code>\"csv\", \"doc\", \"docx\", \"epub\", \"image\", \"md\", \"msg\", \"odt\", \"org\", \"pdf\", \"ppt\", \"pptx\", \"rtf\", \"rst\", \"tsv\", \"xlsx\"</code></li> </ul> <p>Each document added to your bot enhances its ability to understand and respond to queries more effectively, leveraging the rich context provided by diverse data sources.</p>"},{"location":"updating_bots/","title":"Updating Bots","text":""},{"location":"updating_bots/#updating-bots-in-longtrainer","title":"Updating Bots in LongTrainer","text":"<p>LongTrainer allows you to seamlessly update your bots with new documents, links, search queries, and prompt templates. This capability ensures that your bot remains relevant and equipped with the latest information, enhancing its conversational abilities and accuracy.</p>"},{"location":"updating_bots/#parameters-description","title":"Parameters Description","text":"<ul> <li>paths (list): List of file paths from which documents are loaded. These can include local or networked file locations.</li> <li>bot_id (str): The unique identifier for the bot that is being updated.</li> <li>links (list, optional): List of URLs from which to fetch and load content directly into the bot's database.</li> <li>search_query (str, optional): A query string used to perform a search, typically on the internet or a specific database like Wikipedia, to gather content.</li> <li>prompt_template (str, optional): A new or modified prompt template to customize the bot's conversational prompts.</li> <li>use_unstructured (bool): Specifies whether to use unstructured data loaders for documents that do not follow a fixed format or schema.</li> </ul>"},{"location":"updating_bots/#example-usage","title":"Example Usage","text":"<pre><code># Define paths to new documents and other update parameters\npaths = ['new_data/reports.pdf', 'new_data/summary.txt']\nlinks = ['http://example.com/latest-news', 'http://example.com/data']\nsearch_query = \"current trends in AI\"\n\n# Update the bot\ntrainer.update_chatbot(\n    paths=paths,\n    bot_id='your_bot_id',\n    links=links,\n    search_query=search_query,\n    prompt_template=\"Your updated prompt template here\",\n    use_unstructured=True\n)\n\n# Confirm the bot has been updated\nprint(\"Bot updated successfully with new data and configurations.\")\n</code></pre>"}]}